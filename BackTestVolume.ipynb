{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utilities.Functionnalities import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dateObservation = 24\n",
    "nbPool = 6\n",
    "star_time = \"2021-07-21\"\n",
    "hour = \"00:00:00\"\n",
    "ending_time = \"2021-07-24\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download Node Modules for nodeJs\n",
    "### npm install ccxt\n",
    "### npm install csv-writer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "install_package_if_needed(\"ccxt\")\n",
    "install_package_if_needed(\"csv-writer\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1] Data Collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Les Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = {'current_date': pd.to_datetime(['2020-01-02']),\n",
    "        'pool': [['BNB', 'ATD', 'ACC']]}\n",
    "dff = pd.DataFrame(data)\n",
    "dff.set_index('current_date', inplace=True)\n",
    "dff.drop(dff.index, inplace=True)\n",
    "\n",
    "command = 'node ./database/dl_for_quick_analysis.js'\n",
    "path = \"./database/quick_analysis\"\n",
    "ennDate = f\"{ending_time} {hour}\"\n",
    "sttDate = f\"{star_time} {hour}\"\n",
    "start_date = datetime.strptime(sttDate, \"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = datetime.strptime(ennDate, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "current_date = start_date\n",
    "\n",
    "# Define the maximum number of threads\n",
    "MAX_THREADS = 10\n",
    "\n",
    "# Semaphore to control the concurrency\n",
    "semaphore = threading.Semaphore(MAX_THREADS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download all the OHLCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def downloadingDate(current_date):\n",
    "    # Acquire the semaphore\n",
    "    semaphore.acquire()\n",
    "\n",
    "    execute_terminal_command2(command, current_date.strftime(\"%Y-%m-%d\"), hour)\n",
    "    remove_non_csv_files(path)\n",
    "\n",
    "    # Release the semaphore\n",
    "    semaphore.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(path)\n",
    "except:\n",
    "    traceback.format_exc()\n",
    "threads = []\n",
    "while current_date <= end_date:\n",
    "    thread = threading.Thread(target=downloadingDate, args=(current_date,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "print(\"Process is done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extraire all the pair names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_names = []\n",
    "\n",
    "# Get the list of file names in the directory\n",
    "file_names = os.listdir(path)\n",
    "\n",
    "# Process each file name\n",
    "for file_name in file_names:\n",
    "    # Extract the pair name before the '$' character\n",
    "    pair_name = file_name.split('$')[0]\n",
    "\n",
    "    # Add the pair name to the list if it's not already present\n",
    "    if pair_name not in pair_names:\n",
    "        pair_names.append(pair_name)\n",
    "\n",
    "# Print the list of unique pair names\n",
    "print(pair_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the csv files for all the dates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pair_data = {}\n",
    "# Process each file name\n",
    "for file_name in file_names:\n",
    "    # Extract the pair name before the '$' character\n",
    "    pair_name = file_name.split('$')[0]\n",
    "\n",
    "    # Check if the pair name is already in the dictionary\n",
    "    if pair_name in pair_data:\n",
    "        pair_data[pair_name].append(file_name)\n",
    "    else:\n",
    "        pair_data[pair_name] = [file_name]\n",
    "\n",
    "# Iterate over the pair names and their corresponding files\n",
    "for pair_name, files in pair_data.items():\n",
    "    # Create a new file for the pair name\n",
    "    output_file = os.path.join(path, f\"{pair_name}.csv\")\n",
    "\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w', newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out)\n",
    "\n",
    "        # Write the header to the output file\n",
    "        writer.writerow(['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "        # Iterate over the files for the pair name\n",
    "        for file in files:\n",
    "            # Open each input file\n",
    "            with open(os.path.join(path, file), 'r') as csv_in:\n",
    "                reader = csv.reader(csv_in)\n",
    "                next(reader)  # Skip the header row\n",
    "\n",
    "                # Write the data rows to the output file\n",
    "                writer.writerows(reader)\n",
    "\n",
    "    print(f\"Created file: {output_file} with merged data and header.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove rest of csv files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate over the file names\n",
    "for file_name in file_names:\n",
    "    # Check if the file name contains the '$' character\n",
    "    if '$' in file_name:\n",
    "        # Create the file path\n",
    "        file_path = os.path.join(path, file_name)\n",
    "\n",
    "        # Remove the file\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted file: {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove redudancy in the csv files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the list of file names in the directory\n",
    "file_names = os.listdir(path)\n",
    "\n",
    "# Iterate over the file names\n",
    "for file_name in file_names:\n",
    "    # Create the file path\n",
    "    file_path = os.path.join(path, file_name)\n",
    "\n",
    "    # Read the contents of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove repeated rows and keep only the first occurrence\n",
    "    unique_lines = []\n",
    "    unique_set = set()\n",
    "    for line in lines:\n",
    "        if line not in unique_set:\n",
    "            unique_lines.append(line)\n",
    "            unique_set.add(line)\n",
    "\n",
    "    # Write the unique lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(unique_lines)\n",
    "\n",
    "    print(f\"Removed repeated rows from file: {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2] Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_list = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "df_list = {}\n",
    "for file in file_list:\n",
    "    df_list[file[:-9]] = get_historical_from_path(path + \"/\" + file)\n",
    "print(\"All data loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the start and end times to datetime objects\n",
    "start = datetime.strptime(star_time, \"%Y-%m-%d\")\n",
    "end = datetime.strptime(ending_time, \"%Y-%m-%d\")\n",
    "# Define the timedelta for incrementing the date\n",
    "delta = timedelta(days=1)\n",
    "# Loop through the dates between start and end\n",
    "while start <= end:\n",
    "    current_date = start.strftime(\"%Y-%m-%d\")\n",
    "    # Filter the dataframes to keep only the specific date\n",
    "    filtered_dataframes = {}\n",
    "    for key, df in df_list.items():\n",
    "        filtered_df = df.loc[df.index.date == pd.to_datetime(start).date()]\n",
    "        filtered_dataframes[key] = filtered_df\n",
    "    df_metric = get_analyisis_from_window(df_list,dateObservation).sort_values(by=\"volume_evolution\", ascending=False)\n",
    "    dfVe = df_metric.iloc[:nbPool]\n",
    "    market = list(dfVe.index)\n",
    "    dff.loc[datetime.strptime(current_date, \"%Y-%m-%d\")] = [list(dfVe['volume_evolution'].index)]\n",
    "    start += delta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the Pools By day dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dff.to_csv('./database/pools.csv',header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3] Generate All Combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "crypto = {}\n",
    "deltaHours = [\"2h\",\"4h\",\"8h\",\"12h\"]\n",
    "Ni = [\"N\",\"N-1\",\"N-2\"]\n",
    "array1 = []\n",
    "with open('database/pools.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        timestamp = row[0]\n",
    "        elements = row[1].strip('[]').split(', ')\n",
    "        array1.append((timestamp, elements))\n",
    "combinations = list(itertools.product(array1, deltaHours, Ni))\n",
    "combinations = [list(item) for item in combinations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4] Cocotier Process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_historical_klines(x,deltahour,sttDate,ennDate):\n",
    "    # Open the CSV file\n",
    "    file_path = f\"./database/quick_analysis/{x}-USDT.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert sttDate and ennDate to datetime objects\n",
    "    stt_date = pd.to_datetime(sttDate, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    enn_date = pd.to_datetime(ennDate, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Convert the 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "\n",
    "    # Filter the dataframe based on the start and end dates\n",
    "    mask = (df['date'] >= stt_date) & (df['date'] <= enn_date)\n",
    "    filtered_df = df.loc[mask]\n",
    "\n",
    "    # Extract the delta hour value from the string (e.g., '2h', '4h')\n",
    "    delta_hours = int(re.findall(r'\\d+', deltahour)[0])\n",
    "\n",
    "    # Create a time range at delta hour intervals\n",
    "    time_range = pd.date_range(stt_date, enn_date, freq=f'{delta_hours}H')\n",
    "\n",
    "    # Filter the dataframe to keep only the rows at delta hour intervals\n",
    "    filtered_df = filtered_df[filtered_df['date'].isin(time_range)]\n",
    "\n",
    "    # Create a new dataframe with the desired columns\n",
    "    new_df = filtered_df[['date', 'open', 'close']].copy()\n",
    "    new_df.columns = ['timestamp', f'{x.lower()}_open', f'{x.lower()}_close']\n",
    "\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def cocotier(combination):\n",
    "    semaphore.acquire()\n",
    "    crypto = {}\n",
    "    x = \"\"\n",
    "    for elm in combination[0][1] :\n",
    "        try :\n",
    "            x = elm.replace(\"'\",\"\")\n",
    "\n",
    "            crypto[x] = get_historical_klines(x,combination[1],sttDate,ennDate)\n",
    "            crypto[x] = crypto[x].astype({x.lower()+ '_open': 'float64',x.lower()+ '_close': 'float64'})\n",
    "            crypto[x] = crypto[x].set_index('timestamp')\n",
    "        except Exception as ll:\n",
    "            print(f\"{ll}\\n{x}!\")\n",
    "            traceback.format_exc()\n",
    "    try :\n",
    "        array_mauvais_shape = detection_mauvais_shape(crypto)\n",
    "        # crypto = correction_shape(crypto, array_mauvais_shape)\n",
    "        # for elm in array_mauvais_shape:\n",
    "        #     crypto[elm]['timestamp'] = generation_date(crypto[elm], int(delta_hour[:1]))\n",
    "        #     crypto[elm] = crypto[elm].set_index('timestamp')\n",
    "        for i in array_mauvais_shape:\n",
    "            del crypto[i]\n",
    "        crypto = variationN(crypto, combination[2])\n",
    "        crypto = coeffMulti(crypto)\n",
    "        crypto = mergeCryptoTogether(crypto)\n",
    "        crypto, maxis = botMax(crypto)\n",
    "        crypto = botMaxVariation2(crypto, maxis)\n",
    "        crypto = coeffMultiBotMax(crypto)\n",
    "        coefMulti = coefmultiFinal(crypto)\n",
    "        combination.append(coefMulti.tail(1).iloc[-1,-1])\n",
    "    except Exception as ll:\n",
    "        print(f\"{ll}\\n\")\n",
    "    semaphore.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Launch a thread for each iteration\n",
    "threads = []\n",
    "combinations = list(combinations)\n",
    "for combination in combinations:\n",
    "    thread = threading.Thread(target=cocotier, args=(combination,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5] Presenting the First DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Flatten the nested lists\n",
    "flat_data = []\n",
    "for combination in combinations:\n",
    "    datetime = combination[0][0]\n",
    "    pool = combination[0][1]\n",
    "    deltahour = combination[1]\n",
    "    Ni = combination[2]\n",
    "    BotMax = combination[3]\n",
    "    flat_data.append([datetime, deltahour, Ni, BotMax, pool])\n",
    "df = pd.DataFrame(flat_data, columns=['datetime', 'deltahour', 'Ni', 'BotMax','pool'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6] Produit CumulÃ©e and final Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Convert 'datetime' column to datetime format\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Group DataFrame by 'deltahour' and 'Ni', calculate product of 'BotMax'\n",
    "df_grouped = df.groupby(['deltahour', 'Ni']).agg({'datetime': ['min', 'max'], 'BotMax': 'prod'}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "df_grouped.columns = ['deltahour', 'Ni', 'startDate', 'endingDate', 'BotMax']\n",
    "\n",
    "# Convert 'startDate' and 'endingDate' columns to desired format\n",
    "df_grouped['startDate'] = df_grouped['startDate'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_grouped['endingDate'] = df_grouped['endingDate'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   deltahour   Ni            startDate           endingDate    BotMax\n",
      "0        12h    N  2021-07-21 00:00:00  2021-07-24 00:00:00  0.918403\n",
      "1        12h  N-1  2021-07-21 00:00:00  2021-07-24 00:00:00  0.918403\n",
      "2        12h  N-2  2021-07-21 00:00:00  2021-07-24 00:00:00  0.918403\n",
      "3         2h    N  2021-07-21 00:00:00  2021-07-24 00:00:00  1.103001\n",
      "4         2h  N-1  2021-07-21 00:00:00  2021-07-24 00:00:00  1.103001\n",
      "5         2h  N-2  2021-07-21 00:00:00  2021-07-24 00:00:00  1.103001\n",
      "6         4h    N  2021-07-21 00:00:00  2021-07-24 00:00:00  1.120594\n",
      "7         4h  N-1  2021-07-21 00:00:00  2021-07-24 00:00:00  1.120594\n",
      "8         4h  N-2  2021-07-21 00:00:00  2021-07-24 00:00:00  1.120594\n",
      "9         8h    N  2021-07-21 00:00:00  2021-07-24 00:00:00  0.978497\n",
      "10        8h  N-1  2021-07-21 00:00:00  2021-07-24 00:00:00  0.978497\n",
      "11        8h  N-2  2021-07-21 00:00:00  2021-07-24 00:00:00  0.978497\n"
     ]
    }
   ],
   "source": [
    "print(df_grouped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}